{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1 -- PyTorch FFNNs with layer objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll just do a little light text classification with the Reuters \"crude\"-topic and \"grain\"-topic articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch import nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "def load_files(directory, classname):\n",
    "    # Takes a directory name and loads all the .txt as file ids with the classname as classname.\n",
    "    filenames = glob(directory + \"/*.txt\")\n",
    "    return (open(f, \"r\").read() for f in filenames), [classname] * len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the use of the generator expression---it helps us avoid having too many files open at once. Lazy evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crudefiles, y_crude = load_files(\"/scratch/reuters-topics/crude\", \"crude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grainfiles, y_grain = load_files(\"/scratch/reuters-topics/grain\", \"grain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "allfiles = itertools.chain(crudefiles, grainfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're just going to get tfidf vectors in one line, basically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "allvectors = vectorizer.fit_transform(allfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1160x11186 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 117926 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = allvectors.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.01907834, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.01907834, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1160, 11186)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_crude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn has a train/test split facility. PyTorch has some of these sorts of utilities too and we may see them too but they're lower priority since we get most of what we need from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "splits = train_test_split(X, y_crude+y_grain, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928, 232, 928, 232)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits[0]), len(splits[1]), len(splits[2]), len(splits[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = [{'crude':0,'grain':1}[x] for x in Y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = [{'crude':0,'grain':1}[x] for x in Y_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're no longer doing things by hand as in LT2212 but rather by applying the layers from PyTorch.  We shouldn't forget that what's going on is just the same matrix/tensor operations we practiced in LT2212, but with rather metaphorical shortcuts.\n",
    "\n",
    "We treat our two-class problem as binary classification and just apply a sigmoid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data onto the GPU and set up the training environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "classifier = TextClassifier(len(X_train[0]), 200)\n",
    "classifier = classifier.to(dev)\n",
    "\n",
    "X_train_torch = torch.Tensor(X_train)\n",
    "X_train_torch = X_train_torch.to(dev)\n",
    "Y_train_torch = torch.Tensor(Y_train)\n",
    "Y_train_torch = Y_train_torch.to(dev)\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters())\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([928])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_torch[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that `Y_train_torch`'s size is (928) is actually a (minor) problem because it is storing the values as scalars. The network will output 1-dimensional vectors.  So we need something of size (928, 1).\n",
    "\n",
    "We get this by \"unsqueezing\" the first dimension, ie, wrapping all elements along that dimension in a vector. Then we get (928, 1), and get rid of the warning we saw in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_torch = Y_train_torch.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([928, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_torch.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for i in range(len(X_train)):\n",
    "        x = X_train_torch[i]\n",
    "        y = Y_train_torch[i]\n",
    "        optimizer.zero_grad()\n",
    "        output = classifier.forward(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0143,  0.0908,  0.0064,  ..., -0.0077,  0.0211, -0.0046],\n",
       "         [ 0.0123,  0.0589, -0.0083,  ...,  0.0029,  0.0140, -0.0050],\n",
       "         [ 0.0046, -0.0086, -0.0088,  ...,  0.0009,  0.0093, -0.0061],\n",
       "         ...,\n",
       "         [ 0.0110,  0.0823, -0.0094,  ..., -0.0070,  0.0259, -0.0011],\n",
       "         [ 0.0078, -0.0196,  0.0094,  ...,  0.0013,  0.0085,  0.0049],\n",
       "         [ 0.0254, -0.0417,  0.0253,  ..., -0.0016, -0.0199, -0.0003]],\n",
       "        device='cuda:0', requires_grad=True), Parameter containing:\n",
       " tensor([ 0.0364,  0.0348, -0.0130,  0.0321,  0.0682,  0.0372,  0.0837,  0.0814,\n",
       "          0.0811,  0.0333,  0.0325,  0.0694,  0.0325,  0.0709,  0.0309,  0.0625,\n",
       "          0.0398,  0.0778,  0.0766,  0.0350,  0.0775,  0.0722,  0.0757,  0.0376,\n",
       "          0.0269,  0.0306,  0.0380,  0.0393,  0.0371,  0.0331, -0.0163, -0.0187,\n",
       "          0.0562,  0.0806,  0.0435,  0.0312,  0.0481,  0.0607,  0.0793,  0.0780,\n",
       "          0.0309,  0.0762,  0.0366,  0.0383,  0.0334,  0.0750, -0.0146,  0.0345,\n",
       "         -0.0058,  0.0365,  0.0348,  0.0344,  0.0458,  0.0421,  0.0748,  0.0344,\n",
       "          0.0741,  0.0763, -0.0079,  0.0362,  0.0303,  0.0771,  0.0740,  0.0422,\n",
       "         -0.0020, -0.0142,  0.0351,  0.0545, -0.0097,  0.0378,  0.0796,  0.0333,\n",
       "          0.0342,  0.0361,  0.0771,  0.0803,  0.0383,  0.0334,  0.0877,  0.0354,\n",
       "          0.0321, -0.0136,  0.0746,  0.0821,  0.0739,  0.0371,  0.0395, -0.0099,\n",
       "          0.0336,  0.0664,  0.0374, -0.0176,  0.0672,  0.0778,  0.0725,  0.0381,\n",
       "          0.0811,  0.0335, -0.0131,  0.0405,  0.0303,  0.0751, -0.0146,  0.0367,\n",
       "          0.0709,  0.0393,  0.0349, -0.0109,  0.0391,  0.0695,  0.0343,  0.0314,\n",
       "          0.0388,  0.0401, -0.0117,  0.0882, -0.0063,  0.0332,  0.0385,  0.0471,\n",
       "          0.0400,  0.0344,  0.0815,  0.0319,  0.0339,  0.0799,  0.0712,  0.0420,\n",
       "         -0.0124, -0.0107, -0.0139,  0.0336,  0.0388,  0.0353, -0.0068,  0.0797,\n",
       "          0.0689,  0.0418,  0.0701,  0.0724, -0.0184, -0.0147,  0.0403, -0.0149,\n",
       "         -0.0138,  0.0395,  0.0311,  0.0763,  0.0179,  0.0776, -0.0162,  0.0780,\n",
       "          0.0783,  0.0340,  0.0320,  0.0725,  0.0756,  0.0417, -0.0151,  0.0740,\n",
       "         -0.0108,  0.0449,  0.0437,  0.0740,  0.0443,  0.0355,  0.0375,  0.0377,\n",
       "          0.0334,  0.0400, -0.0088, -0.0174, -0.0124,  0.0391,  0.0768,  0.0768,\n",
       "          0.0339,  0.0727,  0.0392,  0.0298,  0.0333,  0.0346,  0.0452,  0.0236,\n",
       "          0.0924,  0.0332,  0.0844,  0.0769,  0.0374,  0.0364, -0.0132,  0.0401,\n",
       "         -0.0125,  0.0883,  0.0733,  0.0353,  0.0754,  0.0374, -0.0075,  0.0759],\n",
       "        device='cuda:0', requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.2295,  0.2647,  0.0199,  0.2448, -0.2854,  0.2424, -0.2739, -0.3044,\n",
       "          -0.2645,  0.2624,  0.2497, -0.3050,  0.2567, -0.2957,  0.2554, -0.3108,\n",
       "           0.2170, -0.2927, -0.2748,  0.2708, -0.3129, -0.2998, -0.2938,  0.2604,\n",
       "           0.2649, -0.1480,  0.2221,  0.2272,  0.2275,  0.2508,  0.0273, -0.0226,\n",
       "          -0.2352, -0.2689,  0.2287,  0.2790, -0.2417, -0.3315, -0.2958, -0.2764,\n",
       "           0.2579, -0.3079,  0.2373,  0.2544,  0.2763, -0.3148,  0.0503,  0.2636,\n",
       "          -0.0313,  0.2584,  0.2617,  0.2309,  0.2130,  0.2564, -0.2892,  0.2746,\n",
       "          -0.2698, -0.2923, -0.1479,  0.2560,  0.2386, -0.2811, -0.2989,  0.2336,\n",
       "           0.1987, -0.0025,  0.2511, -0.1176, -0.0611,  0.2455, -0.2555,  0.2597,\n",
       "           0.2578,  0.2429, -0.2703, -0.2450,  0.2595,  0.2578, -0.2634,  0.2658,\n",
       "           0.2227, -0.0140, -0.3107, -0.2075, -0.3137,  0.2617,  0.2366, -0.0399,\n",
       "           0.2782, -0.2891,  0.2176, -0.0556, -0.3113, -0.3120, -0.2988,  0.2462,\n",
       "          -0.2723,  0.2744,  0.0616,  0.2449,  0.2888, -0.3128, -0.0483,  0.2334,\n",
       "          -0.3103,  0.2402,  0.2696,  0.0042,  0.2338, -0.3053,  0.2594,  0.2482,\n",
       "           0.2391,  0.2410, -0.0306, -0.2885, -0.0431,  0.2549,  0.2417,  0.2206,\n",
       "           0.2415,  0.2741, -0.2786,  0.2483,  0.2783, -0.2729, -0.3143,  0.2272,\n",
       "          -0.0603, -0.0632, -0.0586,  0.2645,  0.2139,  0.2606, -0.0515, -0.3071,\n",
       "          -0.2919,  0.2275, -0.2973, -0.2972, -0.0188,  0.0051,  0.2240,  0.0136,\n",
       "           0.0157,  0.2327,  0.2901, -0.3157,  0.2496, -0.2924, -0.0381, -0.2723,\n",
       "          -0.3089,  0.2981,  0.2716, -0.2887, -0.2990,  0.2189,  0.0579, -0.3042,\n",
       "          -0.0416,  0.2182,  0.2110, -0.2896, -0.1804,  0.2547,  0.2581,  0.2258,\n",
       "           0.2489,  0.2155, -0.0212, -0.0337,  0.0251,  0.2522, -0.2721, -0.2642,\n",
       "           0.2230, -0.3091,  0.2386,  0.2914,  0.2454,  0.2735,  0.2127,  0.2582,\n",
       "          -0.2488,  0.2601, -0.2738, -0.2856,  0.2315,  0.2693, -0.0472,  0.2219,\n",
       "          -0.0572, -0.2524, -0.3227,  0.2572, -0.2592,  0.2262,  0.0007, -0.2451]],\n",
       "        device='cuda:0', requires_grad=True), Parameter containing:\n",
       " tensor([-0.0619], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(classifier.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_torch = torch.Tensor(X_test)\n",
    "X_test_torch = X_test_torch.to(dev)\n",
    "Y_test_torch = torch.Tensor(Y_test)\n",
    "Y_test_torch = Y_test_torch.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    result = []\n",
    "    for i in range(len(X_test)):\n",
    "        x = X_test_torch[i]\n",
    "        result.append(classifier.forward(x).to('cpu'))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_int = [round(float(x[0])) for x in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = [1 if x[0] == x[1] else 0 for x in zip(result_int, Y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698275862068966"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(correct)/len(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like a single epoch with a very simple FFNN model was good enough to get nearly 100% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
