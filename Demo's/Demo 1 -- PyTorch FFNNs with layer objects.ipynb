{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1 -- PyTorch FFNNs with layer objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll just do a little light text classification with the Reuters \"crude\"-topic and \"grain\"-topic articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch import nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "def load_files(directory, classname):\n",
    "    # Takes a directory name and loads all the .txt as file ids with the classname as classname.\n",
    "    filenames = glob(directory + \"/*.txt\")\n",
    "    return (open(f, \"r\").read() for f in filenames), [classname] * len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the use of the generator expression---it helps us avoid having too many files open at once. Lazy evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crudefiles, y_crude = load_files(\"/scratch/reuters-topics/crude\", \"crude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grainfiles, y_grain = load_files(\"/scratch/reuters-topics/grain\", \"grain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "allfiles = itertools.chain(crudefiles, grainfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're just going to get tfidf vectors in one line, basically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "allvectors = vectorizer.fit_transform(allfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1160x11186 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 117926 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = allvectors.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.01907834, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.01907834, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1160, 11186)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_crude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn has a train/test split facility. PyTorch has some of these sorts of utilities too and we may see them too but they're lower priority since we get most of what we need from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "splits = train_test_split(X, y_crude+y_grain, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928, 232, 928, 232)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits[0]), len(splits[1]), len(splits[2]), len(splits[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = [{'crude':0,'grain':1}[x] for x in Y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = [{'crude':0,'grain':1}[x] for x in Y_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're no longer doing things by hand as in LT2212 but rather by applying the layers from PyTorch.  We shouldn't forget that what's going on is just the same matrix/tensor operations we practiced in LT2212, but with rather metaphorical shortcuts.\n",
    "\n",
    "We treat our two-class problem as binary classification and just apply a sigmoid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data onto the GPU and set up the training environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "classifier = TextClassifier(len(X_train[0]), 200)\n",
    "classifier = classifier.to(dev)\n",
    "\n",
    "X_train_torch = torch.Tensor(X_train)\n",
    "X_train_torch = X_train_torch.to(dev)\n",
    "Y_train_torch = torch.Tensor(Y_train)\n",
    "Y_train_torch = Y_train_torch.to(dev)\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters())\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([928])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_torch[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that `Y_train_torch`'s size is (928) is actually a (minor) problem because it is storing the values as scalars. The network will output 1-dimensional vectors.  So we need something of size (928, 1).\n",
    "\n",
    "We get this by \"unsqueezing\" the first dimension, ie, wrapping all elements along that dimension in a vector. Then we get (928, 1), and get rid of the warning we saw in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_torch = Y_train_torch.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([928, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_torch.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for i in range(len(X_train)):\n",
    "        x = X_train_torch[i]\n",
    "        y = Y_train_torch[i]\n",
    "        optimizer.zero_grad()\n",
    "        output = classifier.forward(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0203, -0.0143,  0.0139,  ...,  0.0049, -0.0305,  0.0111],\n",
       "         [ 0.0004, -0.0042,  0.0061,  ...,  0.0004, -0.0016,  0.0044],\n",
       "         [ 0.0365, -0.0179,  0.0149,  ...,  0.0006, -0.0309,  0.0201],\n",
       "         ...,\n",
       "         [ 0.0348,  0.0817, -0.0069,  ...,  0.0019,  0.0212, -0.0038],\n",
       "         [ 0.0610,  0.0563,  0.0220,  ...,  0.0041, -0.0216, -0.0061],\n",
       "         [ 0.0277,  0.1004, -0.0089,  ..., -0.0025,  0.0284, -0.0128]],\n",
       "        device='cuda:0', requires_grad=True), Parameter containing:\n",
       " tensor([ 0.0319, -0.0149,  0.0262, -0.0136,  0.0327,  0.0725,  0.0645,  0.0816,\n",
       "          0.0671,  0.0321,  0.0349, -0.0132,  0.0379,  0.0349,  0.0244,  0.0266,\n",
       "          0.0334,  0.0295,  0.0806,  0.0730, -0.0129,  0.0229,  0.0733,  0.0756,\n",
       "         -0.0122,  0.0743,  0.0223,  0.0691,  0.0283,  0.0768,  0.0307,  0.0238,\n",
       "          0.0842,  0.0701,  0.0289,  0.0295,  0.0767,  0.0778,  0.0777,  0.0774,\n",
       "          0.0784,  0.0779, -0.0187,  0.0343,  0.0380,  0.0283,  0.0343,  0.0710,\n",
       "          0.0288,  0.0340,  0.0325,  0.0332,  0.0774,  0.0722,  0.0318,  0.0223,\n",
       "          0.0818,  0.0678,  0.0244,  0.0699,  0.0763, -0.0121, -0.0114,  0.0339,\n",
       "          0.0285,  0.0297,  0.0269,  0.0712,  0.0343,  0.0685, -0.0161, -0.0154,\n",
       "          0.0687,  0.0755,  0.0239,  0.0251, -0.0142,  0.0256,  0.0735,  0.0683,\n",
       "          0.0276,  0.0749,  0.0393,  0.0353,  0.0715,  0.0709,  0.0308,  0.0332,\n",
       "          0.0813,  0.0705, -0.0114,  0.0669,  0.0292,  0.0308,  0.0332,  0.0276,\n",
       "         -0.0196,  0.0798,  0.0299,  0.0333,  0.0714,  0.0782,  0.0288, -0.0146,\n",
       "          0.0303,  0.0366,  0.0834, -0.0121,  0.0692,  0.0329,  0.0355,  0.0025,\n",
       "          0.0772,  0.0301, -0.0188,  0.0327,  0.0709, -0.0150,  0.0701,  0.0669,\n",
       "          0.0304,  0.0346,  0.0795,  0.0295,  0.0358,  0.0330,  0.0731,  0.0724,\n",
       "          0.0775,  0.0725,  0.0300, -0.0108,  0.0278,  0.0318,  0.0319,  0.0788,\n",
       "          0.0343,  0.0362, -0.0134, -0.0135, -0.0109,  0.0359,  0.0745,  0.0704,\n",
       "         -0.0095,  0.0678,  0.0728,  0.0802,  0.0373,  0.0345,  0.0712,  0.0317,\n",
       "          0.0731, -0.0141,  0.0296,  0.0712,  0.0318,  0.0792,  0.0300, -0.0123,\n",
       "          0.0011,  0.0794, -0.0165,  0.0302,  0.0707,  0.0204,  0.0143,  0.0306,\n",
       "          0.0374,  0.0298,  0.0679,  0.0291,  0.0735,  0.0674,  0.0795,  0.0275,\n",
       "          0.0277,  0.0253,  0.0650,  0.0245,  0.0360,  0.0339, -0.0118,  0.0303,\n",
       "         -0.0143,  0.0688,  0.0659,  0.0722,  0.0324,  0.0737,  0.0269,  0.0275,\n",
       "          0.0341,  0.0236, -0.0129,  0.0311,  0.0686,  0.0688,  0.0193,  0.0834],\n",
       "        device='cuda:0', requires_grad=True), Parameter containing:\n",
       " tensor([[-0.2373,  0.0126, -0.2344,  0.0330, -0.2331,  0.2967,  0.3239,  0.2670,\n",
       "           0.3342,  0.2303, -0.2457, -0.0072, -0.2258, -0.2111, -0.2499, -0.2702,\n",
       "          -0.2273, -0.2338,  0.2730,  0.2867, -0.0603, -0.2432,  0.2891,  0.2645,\n",
       "           0.0412,  0.2841, -0.2117,  0.3200, -0.2798,  0.2925, -0.2631, -0.2528,\n",
       "           0.2654,  0.3080, -0.2198, -0.2594,  0.2853,  0.2801,  0.2843,  0.2805,\n",
       "           0.2807,  0.2820,  0.0589, -0.2331, -0.2068, -0.2586, -0.2022,  0.2966,\n",
       "          -0.2414, -0.1980, -0.2900, -0.2400,  0.3006,  0.2901, -0.2395, -0.2254,\n",
       "           0.2694,  0.2995, -0.2301,  0.2983,  0.2996,  0.0611,  0.0314, -0.2128,\n",
       "          -0.1947, -0.2452, -0.2321,  0.3056, -0.2528,  0.3040,  0.0489, -0.0406,\n",
       "           0.3010,  0.2808, -0.2535, -0.2344, -0.0591, -0.2308,  0.2910,  0.3176,\n",
       "          -0.2567,  0.2901, -0.2218, -0.2076,  0.3060,  0.3232, -0.2280, -0.2526,\n",
       "           0.2629,  0.3212, -0.0568,  0.3185, -0.1998, -0.2381, -0.2363, -0.2061,\n",
       "           0.0233,  0.2714, -0.2399, -0.2168,  0.3042,  0.2738, -0.2710,  0.0166,\n",
       "          -0.2251, -0.2797,  0.2612,  0.0050,  0.3169, -0.2446, -0.2313, -0.1502,\n",
       "           0.3041, -0.2427, -0.0327, -0.2198,  0.2949, -0.0600,  0.3066,  0.3022,\n",
       "          -0.2069, -0.2290,  0.2769, -0.2865, -0.2057, -0.2383,  0.2781,  0.2920,\n",
       "           0.2796,  0.3130, -0.2315,  0.0328, -0.2561, -0.2109, -0.2486,  0.2734,\n",
       "          -0.2553, -0.1867,  0.0363,  0.0493, -0.0367, -0.2292,  0.2955,  0.3237,\n",
       "          -0.0055,  0.3147,  0.3100,  0.2733, -0.2143, -0.2241,  0.3103, -0.2529,\n",
       "           0.2975, -0.0766, -0.2338,  0.2992, -0.2550,  0.2751, -0.2684,  0.0505,\n",
       "          -0.2029,  0.3064,  0.0078, -0.2120,  0.3117, -0.2848, -0.2932, -0.2361,\n",
       "          -0.2043, -0.2413,  0.3138, -0.2457,  0.2987,  0.2962,  0.2744, -0.2456,\n",
       "          -0.2563, -0.2410,  0.3047, -0.2366, -0.2369, -0.2369,  0.0323, -0.2310,\n",
       "          -0.0190,  0.3226,  0.3136,  0.3016, -0.2208,  0.3048, -0.2553, -0.2460,\n",
       "          -0.1983, -0.2594,  0.0356, -0.2433,  0.3056,  0.3145, -0.1819,  0.2754]],\n",
       "        device='cuda:0', requires_grad=True), Parameter containing:\n",
       " tensor([0.0092], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(classifier.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_torch = torch.Tensor(X_test)\n",
    "X_test_torch = X_test_torch.to(dev)\n",
    "Y_test_torch = torch.Tensor(Y_test)\n",
    "Y_test_torch = Y_test_torch.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    result = []\n",
    "    for i in range(len(X_test)):\n",
    "        x = X_test_torch[i]\n",
    "        result.append(classifier.forward(x).to('cpu'))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_int = [round(float(x[0])) for x in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = [1 if x[0] == x[1] else 0 for x in zip(result_int, Y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9870689655172413"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(correct)/len(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like a single epoch with a very simple FFNN model was good enough to get nearly 100% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
